{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Anil-matcha/ChatPDF/blob/main/Gemini_ChatPDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V6pj2_r8Pbx"
   },
   "source": [
    "ChatPDF flow\n",
    "\n",
    "![ChatPDF flow](https://miro.medium.com/v2/resize:fit:1400/1*leoW-Pn0ohWalrUBbzdidA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H6RsKxj4Rxt"
   },
   "source": [
    "Setup Google api key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5PpWJiu32_rI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBk9AIIIZ2GzX4Jsclq-zY4Hqzh2l9m36s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cT2EMASV4aCm"
   },
   "source": [
    "Install requried dependancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6O5CTvJzPZ6T",
    "outputId": "38b6eac2-828c-47ba-b9d9-606cefd5ec8b"
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet langchain-google-genai langchain faiss-cpu pypdf sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba_-ophd4nwH"
   },
   "source": [
    "Add necessary imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsKZYeSf4im_"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e156mdeh4xZq"
   },
   "source": [
    "Load the documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bpef2RpP3N_o"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"in.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhNGhtHe4y5a"
   },
   "source": [
    "Create a vector db index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZa9CsMY3Peo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.faiss.FAISS object at 0x000001E636893E00>\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(pages, embeddings)\n",
    "print(db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4bkl40C45nl"
   },
   "source": [
    "Search relevant docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ8-IEnG3Rhd"
   },
   "outputs": [],
   "source": [
    "# abc=<langchain_community.vectorstores.faiss.FAISS at 0x16e26d4be90>\n",
    "query =  \"what is the toatal tax\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8i6Xnes5Kg2"
   },
   "source": [
    "Invoke Gemini api with the qa prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "qw6FRgUz3ZBc",
    "outputId": "af31e57c-c3ee-4fbb-81d6-0728ab05f764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83.74'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"\\n\".join([x.page_content for x in docs])\n",
    "qa_prompt = \"Use the following pieces of context to answer the user's question. If you don't know the answer, just say that you don't know, don't try to make up an answer.----------------\"\n",
    "input_text = qa_prompt+\"\\nContext:\"+content+\"\\nUser question:\\n\"+query\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "result = llm.invoke(input_text)\n",
    "result.content"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5Se2cWEHsjMjNgFwBd1HT",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
